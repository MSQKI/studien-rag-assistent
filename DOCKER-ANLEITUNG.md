# ğŸ³ Docker Setup - VollstÃ¤ndige Anleitung

Diese Anleitung zeigt dir Schritt-fÃ¼r-Schritt, wie du den Studien-RAG-Assistenten mit Docker betreibst.

## ğŸ“‹ Voraussetzungen

### Windows
- **Docker Desktop fÃ¼r Windows**
  - Download: https://www.docker.com/products/docker-desktop/
  - **Wichtig**: WSL 2 wird benÃ¶tigt (wird bei Installation automatisch eingerichtet)

### macOS
- **Docker Desktop fÃ¼r Mac**
  - Download: https://www.docker.com/products/docker-desktop/

### Linux
- **Docker Engine** + **Docker Compose**
  ```bash
  # Ubuntu/Debian
  sudo apt-get update
  sudo apt-get install docker.io docker-compose

  # Starte Docker
  sudo systemctl start docker
  sudo systemctl enable docker
  ```

---

## âœ… Schritt 1: Docker Installation prÃ¼fen

Nach der Installation von Docker Desktop:

```bash
# Docker-Version prÃ¼fen
docker --version

# Sollte zeigen: Docker version 24.x.x oder hÃ¶her

# Docker Compose prÃ¼fen
docker-compose --version

# Sollte zeigen: Docker Compose version v2.x.x oder hÃ¶her
```

**Windows**: Stelle sicher, dass Docker Desktop lÃ¤uft (Icon in der Taskleiste)

---

## âœ… Schritt 2: .env Datei erstellen

Die `.env` Datei enthÃ¤lt deine Konfiguration (insbesondere den OpenAI API Key).

### Option A: Kopieren und bearbeiten

```bash
# Im Projekt-Verzeichnis
cp .env.example .env

# Windows PowerShell
Copy-Item .env.example .env
```

### Option B: Manuell erstellen

Erstelle eine Datei namens `.env` im Projekt-Root mit folgendem Inhalt:

```env
# OpenAI API Configuration (REQUIRED)
OPENAI_API_KEY=sk-proj-dein-api-key-hier

# Optional - Model Configuration
LLM_MODEL=gpt-4o-mini
EMBEDDING_MODEL=text-embedding-3-small
TEMPERATURE=0.2
MAX_TOKENS=2000

# Optional - Document Processing
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# Optional - Application Settings
LOG_LEVEL=INFO
```

**âš ï¸ WICHTIG:** Trage deinen echten OpenAI API Key ein!

---

## âœ… Schritt 3: Docker Image bauen

```bash
# Navigiere zum docker/ Verzeichnis
cd docker

# Docker Image bauen (dauert 5-10 Minuten beim ersten Mal)
docker-compose build
```

**Was passiert:**
- âœ… Python 3.11 Base Image wird heruntergeladen
- âœ… Dependencies aus `requirements.txt` werden installiert
- âœ… Anwendungscode wird kopiert
- âœ… Multi-stage Build optimiert die Image-GrÃ¶ÃŸe

**Erwartete Ausgabe:**
```
[+] Building 234.5s (12/12) FINISHED
 => [internal] load build definition
 => => transferring dockerfile
 => [internal] load .dockerignore
 => [stage-1 1/6] FROM docker.io/library/python:3.11-slim
 ...
 => exporting to image
 => => naming to docker.io/library/docker-rag-assistant
```

---

## âœ… Schritt 4: Container starten

```bash
# Container im Hintergrund starten
docker-compose up -d
```

**Flags:**
- `-d` = detached mode (lÃ¤uft im Hintergrund)

**Erwartete Ausgabe:**
```
[+] Running 2/2
 âœ” Network docker_rag-network  Created
 âœ” Container studien-rag-assistent  Started
```

---

## âœ… Schritt 5: Container-Status prÃ¼fen

```bash
# Laufende Container anzeigen
docker-compose ps

# Sollte zeigen:
NAME                     STATUS    PORTS
studien-rag-assistent    Up        0.0.0.0:8501->8501/tcp
```

---

## âœ… Schritt 6: Logs anschauen

```bash
# Live-Logs anzeigen
docker-compose logs -f

# Nur letzte 50 Zeilen
docker-compose logs --tail=50

# Logs eines bestimmten Services
docker-compose logs rag-assistant
```

**Erfolgreiche Logs sollten zeigen:**
```
studien-rag-assistent | You can now view your Streamlit app in your browser.
studien-rag-assistent | URL: http://0.0.0.0:8501
studien-rag-assistent | INFO:src.rag_chain:Initialized RAG Assistant
studien-rag-assistent | INFO:src.vector_store:Initialized OpenAI embeddings
```

**Mit `Ctrl+C` beenden (Container lÃ¤uft weiter im Hintergrund!)**

---

## âœ… Schritt 7: Anwendung Ã¶ffnen

Ã–ffne deinen Browser und navigiere zu:

```
http://localhost:8501
```

ğŸ‰ **Die Anwendung lÃ¤uft!**

---

## ğŸ”§ Docker-Befehle Cheat Sheet

### Container verwalten

```bash
# Container starten
docker-compose up -d

# Container stoppen
docker-compose down

# Container neu starten
docker-compose restart

# Container stoppen UND Volumes lÃ¶schen (ACHTUNG: Daten gehen verloren!)
docker-compose down -v
```

### Logs und Debugging

```bash
# Live-Logs
docker-compose logs -f

# Fehlersuche: In Container einloggen
docker-compose exec rag-assistant /bin/bash

# Im Container dann:
ls -la
python --version
env | grep OPENAI
```

### Updates und Rebuilds

```bash
# Nach Code-Ã„nderungen: Image neu bauen
docker-compose build --no-cache

# Container mit neuem Image neu starten
docker-compose up -d --force-recreate
```

### Speicher aufrÃ¤umen

```bash
# Gestoppte Container lÃ¶schen
docker container prune

# Ungenutzte Images lÃ¶schen
docker image prune

# Alles aufrÃ¤umen (VORSICHT!)
docker system prune -a
```

---

## ğŸ“‚ Persistente Daten

Die folgenden Verzeichnisse werden als Volumes gemountet (Daten bleiben erhalten):

```yaml
volumes:
  - ../data/chroma_db:/app/data/chroma_db    # Vektordatenbank
  - ../data/uploads:/app/data/uploads        # Hochgeladene PDFs
```

**Das bedeutet:**
- âœ… Dokumente bleiben auch nach Container-Neustart erhalten
- âœ… ChromaDB-Daten sind persistent
- âš ï¸ Nur bei `docker-compose down -v` werden Volumes gelÃ¶scht!

---

## ğŸ› Troubleshooting

### Problem 1: "Port 8501 already in use"

**Ursache:** Port ist bereits belegt (z.B. durch lokale Streamlit-Instanz)

**LÃ¶sung 1:** Stoppe die lokale Instanz
```bash
# Alle Python-Prozesse anzeigen
tasklist | findstr python    # Windows
ps aux | grep python         # Linux/Mac

# Prozess beenden (ersetze <PID>)
taskkill /F /PID <PID>       # Windows
kill <PID>                   # Linux/Mac
```

**LÃ¶sung 2:** Ã„ndere den Port in `docker-compose.yml`
```yaml
ports:
  - "8502:8501"  # Nutze Port 8502 statt 8501
```

Dann: http://localhost:8502

---

### Problem 2: "ERROR: Cannot connect to Docker daemon"

**Windows:**
- Stelle sicher, dass Docker Desktop lÃ¤uft
- PrÃ¼fe das Icon in der Taskleiste
- Starte Docker Desktop neu

**Linux:**
```bash
# Docker-Service starten
sudo systemctl start docker

# Nutzer zur docker-Gruppe hinzufÃ¼gen (einmalig)
sudo usermod -aG docker $USER
# Danach: Neu einloggen!
```

---

### Problem 3: "OpenAI API error" im Container

**PrÃ¼fen:**
```bash
# In Container einloggen
docker-compose exec rag-assistant /bin/bash

# Environment Variable prÃ¼fen
echo $OPENAI_API_KEY

# Sollte deinen Key zeigen, NICHT "your_openai_api_key_here"
```

**LÃ¶sung:**
1. `.env` Datei korrigieren
2. Container neu starten:
   ```bash
   docker-compose down
   docker-compose up -d
   ```

---

### Problem 4: "Build failed" oder "pip install error"

**Ursache:** Netzwerkprobleme oder Cache-Fehler

**LÃ¶sung:**
```bash
# Clean Build ohne Cache
docker-compose build --no-cache

# Falls immer noch Fehler: Docker komplett neu starten
# Windows: Docker Desktop > Troubleshoot > Restart Docker Desktop
# Linux:
sudo systemctl restart docker
```

---

### Problem 5: Container startet, aber App nicht erreichbar

**PrÃ¼fen:**
```bash
# Container-Status
docker-compose ps

# Health-Check
docker-compose exec rag-assistant curl -f http://localhost:8501/_stcore/health

# Sollte zeigen: OK
```

**Logs anschauen:**
```bash
docker-compose logs rag-assistant | grep ERROR
```

---

## ğŸ”’ Sicherheit & Best Practices

### 1. API Keys schÃ¼tzen

âœ… **RICHTIG:**
```bash
# .env ist in .gitignore
# .env ist in .dockerignore
# API Key wird via Environment Variable Ã¼bergeben
```

âŒ **FALSCH:**
```python
# NIEMALS im Code:
api_key = "sk-proj-123456..."
```

### 2. Production Deployment

FÃ¼r Production solltest du zusÃ¤tzlich:

```yaml
# docker-compose.yml erweitern mit:
services:
  rag-assistant:
    # Restart Policy
    restart: always

    # Resource Limits
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
        reservations:
          cpus: '1'
          memory: 2G

    # Read-only filesystem (auÃŸer Volumes)
    read_only: true

    # Health Check verschÃ¤rfen
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8501/_stcore/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
```

### 3. Logs rotieren

```yaml
# Logging konfigurieren
logging:
  driver: "json-file"
  options:
    max-size: "10m"
    max-file: "3"
```

---

## ğŸ“Š Performance-Optimierung

### Multi-Stage Build nutzen (bereits implementiert âœ…)

Der Dockerfile nutzt bereits Multi-Stage Build fÃ¼r kleinere Images:

```dockerfile
# Stage 1: Builder (mit Build-Dependencies)
FROM python:3.11-slim as builder
# ... pip install ...

# Stage 2: Runtime (nur Runtime-Dependencies)
FROM python:3.11-slim
COPY --from=builder /root/.local /root/.local
```

**Ergebnis:** Image ist ~1.5 GB statt ~3 GB

### Caching verbessern

```bash
# requirements.txt zuerst kopieren fÃ¼r besseres Caching
COPY requirements.txt .
RUN pip install -r requirements.txt
# Dann erst Code kopieren
COPY . .
```

---

## ğŸš€ Production Deployment

### Mit Docker Swarm

```bash
# Swarm initialisieren
docker swarm init

# Stack deployen
docker stack deploy -c docker-compose.yml rag-stack

# Services anzeigen
docker service ls
```

### Mit Kubernetes

FÃ¼r Kubernetes brauchst du zusÃ¤tzlich:
- `deployment.yaml`
- `service.yaml`
- `configmap.yaml` (fÃ¼r Config)
- `secret.yaml` (fÃ¼r API Keys)

---

## âœ… Checkliste fÃ¼r erfolgreichen Docker-Start

- [ ] Docker Desktop installiert und lÃ¤uft
- [ ] `.env` Datei mit gÃ¼ltigem OpenAI API Key erstellt
- [ ] `docker-compose build` erfolgreich
- [ ] `docker-compose up -d` erfolgreich
- [ ] `docker-compose ps` zeigt "Up"
- [ ] Browser Ã¶ffnet http://localhost:8501
- [ ] PDF-Upload funktioniert
- [ ] Frage wird erfolgreich beantwortet

---

## ğŸ†˜ Weitere Hilfe

Bei Problemen:
1. PrÃ¼fe die [Troubleshooting-Sektion](#-troubleshooting)
2. Schau dir die Logs an: `docker-compose logs -f`
3. Lies die [vollstÃ¤ndige Dokumentation](README.md)
4. Ã–ffne ein Issue auf GitHub

---

## ğŸ¯ Zusammenfassung

**Minimale Befehle fÃ¼r Start:**
```bash
# 1. .env erstellen und API Key eintragen
cp .env.example .env

# 2. In docker/ Verzeichnis wechseln
cd docker

# 3. Bauen und starten
docker-compose up -d

# 4. Browser Ã¶ffnen
# http://localhost:8501
```

**Das war's!** ğŸ‰

---

**Happy Dockering! ğŸ³**
