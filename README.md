# ğŸ“š Studien-RAG-Assistent

Ein state-of-the-art RAG (Retrieval-Augmented Generation) System fÃ¼r Studierende zum intelligenten Durchsuchen und Befragen von Vorlesungsunterlagen mit automatischen Quellenangaben.

## ğŸ¯ Features

- **PDF-Verarbeitung**: Automatische Verarbeitung von Vorlesungs-PDFs mit intelligenter Chunking-Strategie
- **Intelligente Suche**: Semantische Suche Ã¼ber alle hochgeladenen Dokumente mit ChromaDB
- **Chat-Interface**: Konversationsbasierte Interaktion mit Kontext-VerstÃ¤ndnis
- **Quellenangaben**: Automatische Quellenangaben mit Seitenzahlen fÃ¼r jede Antwort
- **Batch Processing**: Effiziente Verarbeitung mehrerer Dokumente gleichzeitig
- **Docker Support**: Einfaches Deployment mit Docker und docker-compose
- **Persistente Speicherung**: Alle Dokumente werden persistent in ChromaDB gespeichert

## ğŸ—ï¸ Technischer Stack

- **Python 3.11+**
- **LangChain**: RAG-Pipeline und Conversation Management
- **ChromaDB**: Lokale, persistente Vektordatenbank
- **OpenAI API**:
  - `gpt-4o-mini` fÃ¼r Chat-Antworten
  - `text-embedding-3-small` fÃ¼r Embeddings
- **Streamlit**: Modernes Web-Interface
- **Docker**: Containerisierung fÃ¼r einfaches Deployment

## ğŸ“¦ Installation

### Voraussetzungen

- Python 3.11 oder hÃ¶her
- OpenAI API Key ([hier erhalten](https://platform.openai.com/api-keys))
- Optional: Docker und docker-compose fÃ¼r Container-Deployment

### Lokale Installation

1. **Repository klonen:**
   ```bash
   git clone <repository-url>
   cd studien-rag-assistent
   ```

2. **Virtuelle Umgebung erstellen:**
   ```bash
   python -m venv .venv

   # Windows
   .venv\Scripts\activate

   # macOS/Linux
   source .venv/bin/activate
   ```

3. **Dependencies installieren:**
   ```bash
   pip install -r requirements.txt
   ```

4. **Umgebungsvariablen konfigurieren:**
   ```bash
   # .env Datei aus Vorlage erstellen
   cp .env.example .env

   # .env Datei bearbeiten und OpenAI API Key eintragen
   ```

5. **Anwendung starten:**
   ```bash
   python run.py
   ```

   Die Anwendung ist dann unter http://localhost:8501 verfÃ¼gbar.

### Docker Installation

1. **Docker Image bauen und starten:**
   ```bash
   cd docker
   docker-compose up -d
   ```

2. **Logs anzeigen:**
   ```bash
   docker-compose logs -f
   ```

3. **Anwendung stoppen:**
   ```bash
   docker-compose down
   ```

Die Anwendung ist dann unter http://localhost:8501 verfÃ¼gbar.

## ğŸš€ Nutzung

### 1. Dokumente hochladen

1. Klicke auf "PDF-Dateien auswÃ¤hlen" in der Seitenleiste
2. WÃ¤hle eine oder mehrere PDF-Dateien aus deinen Vorlesungsunterlagen
3. Klicke auf "Dokumente verarbeiten"
4. Warte, bis die Verarbeitung abgeschlossen ist

### 2. Fragen stellen

1. Gib deine Frage in das Chat-Eingabefeld ein
2. DrÃ¼cke Enter oder klicke auf das Senden-Symbol
3. Die KI analysiert deine Dokumente und gibt eine Antwort mit Quellenangaben

### 3. Quellenangaben prÃ¼fen

- Jede Antwort enthÃ¤lt automatische Quellenangaben
- Klicke auf "Quellenangaben" um Details zu sehen:
  - Dateiname
  - Seitenzahl
  - Relevanter Textausschnitt

### 4. Dokumente verwalten

- LÃ¶sche einzelne Dokumente mit dem ğŸ—‘ï¸ Symbol
- LÃ¶sche die gesamte Konversation mit "Konversation lÃ¶schen"
- Setze alles zurÃ¼ck mit "Alles zurÃ¼cksetzen"

## âš™ï¸ Konfiguration

Die Anwendung kann Ã¼ber die `.env` Datei konfiguriert werden:

```bash
# Erforderlich
OPENAI_API_KEY=your_api_key_here

# Optional - Modell-Konfiguration
LLM_MODEL=gpt-4o-mini                    # Chat-Modell
EMBEDDING_MODEL=text-embedding-3-small   # Embedding-Modell
TEMPERATURE=0.2                          # KreativitÃ¤t (0.0-2.0)
MAX_TOKENS=2000                          # Max. AntwortlÃ¤nge

# Optional - Chunking-Konfiguration
CHUNK_SIZE=1000                          # Chunk-GrÃ¶ÃŸe in Zeichen
CHUNK_OVERLAP=200                        # Ãœberlappung zwischen Chunks

# Optional - Storage
CHROMA_PERSIST_DIR=./data/chroma_db      # ChromaDB Speicherort
UPLOAD_DIR=./data/uploads                # Upload-Verzeichnis

# Optional - Retrieval
RETRIEVAL_K=4                            # Anzahl relevanter Dokumente

# Optional - Anwendung
LOG_LEVEL=INFO                           # Logging-Level
BATCH_SIZE=10                            # Batch-GrÃ¶ÃŸe fÃ¼r Processing
```

## ğŸ“ Projektstruktur

```
studien-rag-assistent/
â”œâ”€â”€ .claude/                  # Claude Code Konfiguration
â”‚   â”œâ”€â”€ CLAUDE.md            # Entwicklungsrichtlinien
â”‚   â””â”€â”€ settings.json        # Editor-Einstellungen
â”œâ”€â”€ docker/                   # Docker-Konfiguration
â”‚   â”œâ”€â”€ Dockerfile           # Container-Definition
â”‚   â””â”€â”€ docker-compose.yml   # Service-Orchestrierung
â”œâ”€â”€ src/                      # Quellcode
â”‚   â”œâ”€â”€ config.py            # Zentrale Konfiguration
â”‚   â”œâ”€â”€ document_processor.py # PDF-Verarbeitung
â”‚   â”œâ”€â”€ vector_store.py      # ChromaDB Integration
â”‚   â”œâ”€â”€ rag_chain.py         # RAG-Pipeline
â”‚   â””â”€â”€ ui.py                # Streamlit Interface
â”œâ”€â”€ data/                     # Daten (persistent)
â”‚   â”œâ”€â”€ uploads/             # Hochgeladene PDFs
â”‚   â””â”€â”€ chroma_db/           # Vektordatenbank
â”œâ”€â”€ tests/                    # Unit & Integration Tests
â”œâ”€â”€ requirements.txt          # Python Dependencies
â”œâ”€â”€ .env.example             # Umgebungsvariablen-Vorlage
â”œâ”€â”€ run.py                   # Start-Script
â””â”€â”€ README.md                # Diese Datei
```

## ğŸ§ª Tests

Tests ausfÃ¼hren:

```bash
# Alle Tests
pytest

# Mit Coverage
pytest --cov=src --cov-report=html

# Bestimmte Test-Datei
pytest tests/test_document_processor.py
```

## ğŸ”§ Entwicklung

### Code Quality Tools

```bash
# Code formatieren
black src/ tests/

# Imports sortieren
isort src/ tests/

# Linting
flake8 src/ tests/

# Type checking
mypy src/
```

### Best Practices

- **Type Hints**: Verwende Type Hints in allen Funktionen
- **Docstrings**: Dokumentiere alle Ã¶ffentlichen Funktionen
- **Error Handling**: Implementiere proper try-except BlÃ¶cke
- **Logging**: Nutze logging statt print statements
- **Tests**: Schreibe Tests fÃ¼r neue Features

## ğŸ“Š Architektur

```
User Interface (Streamlit)
    â†“
RAG Chain (LangChain)
    â†“
Vector Store (ChromaDB) â†â†’ Document Processor
    â†“
OpenAI API (Embeddings & LLM)
```

### Komponenten

1. **Document Processor**:
   - LÃ¤dt PDF-Dateien
   - Extrahiert Text mit PyPDFLoader
   - Chunked Text mit RecursiveCharacterTextSplitter

2. **Vector Store**:
   - Speichert Embeddings in ChromaDB
   - Implementiert Similarity Search
   - Verwaltet Collections

3. **RAG Chain**:
   - Conversational Retrieval Chain
   - Conversation Memory
   - Custom Prompts fÃ¼r deutsche Antworten

4. **UI**:
   - File Upload & Management
   - Chat Interface
   - Source Citations Display

## ğŸ› Troubleshooting

### Problem: "OpenAI API key not found"
**LÃ¶sung**: ÃœberprÃ¼fe, ob die `.env` Datei existiert und `OPENAI_API_KEY` gesetzt ist.

### Problem: "ChromaDB collection error"
**LÃ¶sung**: LÃ¶sche das `data/chroma_db` Verzeichnis und starte neu.

### Problem: "PDF kann nicht geladen werden"
**LÃ¶sung**: Stelle sicher, dass die PDF-Datei nicht beschÃ¤digt ist und nicht passwortgeschÃ¼tzt.

### Problem: Docker Container startet nicht
**LÃ¶sung**:
```bash
docker-compose logs
docker-compose down -v
docker-compose up --build
```

## ğŸ”’ Sicherheit

- **API Keys**: Niemals API Keys in Git committen
- **Secrets**: Verwende `.env` fÃ¼r sensitive Daten
- **Input Validation**: PDFs werden auf GÃ¼ltigkeit geprÃ¼ft
- **Error Handling**: Graceful degradation bei Fehlern

## ğŸ“ Lizenz

Dieses Projekt ist unter der MIT Lizenz lizenziert.

## ğŸ¤ Contributing

Contributions sind willkommen! Bitte:

1. Fork das Repository
2. Erstelle einen Feature Branch
3. Committe deine Ã„nderungen
4. Push zum Branch
5. Ã–ffne einen Pull Request

## ğŸ“§ Support

Bei Fragen oder Problemen:
- Ã–ffne ein Issue im Repository
- Kontaktiere das Entwicklungsteam

## ğŸ“ Credits

Entwickelt mit:
- [LangChain](https://github.com/langchain-ai/langchain)
- [ChromaDB](https://github.com/chroma-core/chroma)
- [Streamlit](https://streamlit.io/)
- [OpenAI API](https://openai.com/)

---

**Made with â¤ï¸ for students**
